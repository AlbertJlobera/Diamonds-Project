<center><h1> Diamonds Project</h1></center>

<h2> We participated in a Kaggle competition to prove some algorithms models to know which one would be te acurate.</h2>



<center><img src='https://github.com/AlbertJlobera/Diamonds-Project/blob/master/IMG/diamond.jpeg?raw=true'></center>



<p> Empezamos informandonos sobre la data acerca de caracteristicas de los diamantes, de la cual destacamos: </p>

<strong> Color:</strong> <i> D - E - F - G - H - I - J - K - L - M </i> where D is the most colorless and M the Faint to light color.




<strong>Clarity:</strong> <i> IF - VVS1 - VVS2 - VS1 - VS2 - SI1 - SI2 - I1 </i> where IF are immaculate diamonds and I1 those with inclusions and notorious marks.





<strong> Cut: </strong> <i>Ideal - Premium - Very Good - Good - Fair </i> where Ideal is the best cut.





<p>Once we know the data menaing, we cleaned the dataset. We transformed the object data to numeric data, 
giving more relevance to the most expensive features.</p>

<p> Then we started training our clean dataset with some models: </p>

<strong>RANDOM FOREST REGRESSOR</strong> 


<strong>KNEIGHBORSREGRESSOR</strong>


<strong>GRADIENT BOOSTING REGRESSOR</strong>


<strong>SVR</strong>


The main goal was to know which model gave us the lower RMSE and moved it to Kaggle competition.

<center><h2>You may ask, What was my score?</h2></center>

<img src='https://github.com/AlbertJlobera/Diamonds-Project/blob/master/IMG/winkaggle.png?raw=true'>
