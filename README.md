<p align="center"><h1> Diamonds Project</h1></p>

<h2> We participated in a Kaggle competition to prove some algorithms models to know which one would be te acurate.</h2>



<p align="center"><img src='https://github.com/AlbertJlobera/Diamonds-Project/blob/master/IMG/diamond.jpeg?raw=true'></p>



<p> We started by searching about the data characteristics of the diamonds of which we highlight:  </p>

<strong> Color:</strong> <i> D - E - F - G - H - I - J - K - L - M </i> where D is the most colorless and M the Faint to light color.




<strong>Clarity:</strong> <i> IF - VVS1 - VVS2 - VS1 - VS2 - SI1 - SI2 - I1 </i> where IF are immaculate diamonds and I1 those with inclusions and notorious marks.





<strong> Cut: </strong> <i>Ideal - Premium - Very Good - Good - Fair </i> where Ideal is the best cut.





<p>Once we know the data menaing, we cleaned the dataset. We transformed the object data to numeric data, 
giving more relevance to the most expensive features.</p>

<p> Then we started training our clean dataset with some models: </p>

<strong>-> RANDOM FOREST REGRESSOR</strong> 


<strong>-> KNEIGHBORSREGRESSOR</strong>


<strong>-> GRADIENT BOOSTING REGRESSOR</strong>


<strong>-> SVR</strong>


The main goal was to know which model gave us the lower RMSE and moved it to Kaggle competition.

<p align="center"><h2>You may ask, What was my score?</h2></p>

<img src='https://github.com/AlbertJlobera/Diamonds-Project/blob/master/IMG/winkaggle.png?raw=true'>
